{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class0' 'class1' 'class11' 'class12' 'class13' 'class14' 'class15'\n",
      " 'class2' 'class3' 'class4' 'class5' 'class6' 'class7' 'class8' 'class9']\n",
      "['class0' 'class1' 'class10' 'class2' 'class3' 'class4' 'class5' 'class6'\n",
      " 'class7' 'class8' 'class9']\n"
     ]
    }
   ],
   "source": [
    "dataset0_classes = os.listdir('dataset0/train/')\n",
    "dataset0_label_encoder = LabelEncoder()\n",
    "\n",
    "dataset0_label_encoder.fit(dataset0_classes)\n",
    "print(dataset0_label_encoder.classes_)\n",
    "\n",
    "dataset1_classes = os.listdir('dataset1/train/')\n",
    "dataset1_label_encoder = LabelEncoder()\n",
    "\n",
    "dataset1_label_encoder.fit(dataset1_classes)\n",
    "print(dataset1_label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_dir = 'dataset0/'\n",
    "dataset1_dir = 'dataset1/'\n",
    "\n",
    "dataset0_train_dir = dataset0_dir + 'train/'\n",
    "dataset0_test_dir = dataset0_dir + 'test/'\n",
    "\n",
    "dataset1_train_dir = dataset1_dir + 'train/'\n",
    "dataset1_test_dir = dataset1_dir + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(data_path):\n",
    "    data_dict = dict()\n",
    "    for cls in os.listdir(data_path):\n",
    "        data_dict[cls] = len(os.listdir(os.path.join(data_path, cls)))\n",
    "    data_dict = list(sorted(data_dict.items(), key = lambda item: item[1], reverse=True))\n",
    "    key = [i[0][5:] for i in data_dict]\n",
    "    value = [i[1] for i in data_dict]\n",
    "    return data_dict, key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('class1', 3504),\n",
      " ('class0', 3446),\n",
      " ('class4', 1098),\n",
      " ('class2', 1098),\n",
      " ('class6', 730),\n",
      " ('class15', 728),\n",
      " ('class5', 487),\n",
      " ('class9', 480),\n",
      " ('class8', 478),\n",
      " ('class12', 386),\n",
      " ('class14', 384),\n",
      " ('class13', 384),\n",
      " ('class11', 384),\n",
      " ('class3', 222),\n",
      " ('class7', 152)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(12,7))\n",
    "data0_train, key, value = get_count(dataset0_train_dir)\n",
    "pp.pprint(data0_train)\n",
    "axes.bar(key, value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('class1', 1751),\n",
      " ('class0', 1723),\n",
      " ('class4', 549),\n",
      " ('class2', 549),\n",
      " ('class6', 365),\n",
      " ('class15', 364),\n",
      " ('class5', 243),\n",
      " ('class9', 240),\n",
      " ('class8', 238),\n",
      " ('class14', 192),\n",
      " ('class11', 192),\n",
      " ('class12', 192),\n",
      " ('class13', 191),\n",
      " ('class3', 110),\n",
      " ('class7', 76)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(12,7))\n",
    "data0_test, key, value = get_count(dataset0_test_dir)\n",
    "pp.pprint(data0_test)\n",
    "axes.bar(key, value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('class3', 686),\n",
      " ('class1', 333),\n",
      " ('class4', 307),\n",
      " ('class5', 152),\n",
      " ('class0', 85),\n",
      " ('class2', 49),\n",
      " ('class7', 48),\n",
      " ('class6', 36),\n",
      " ('class9', 24),\n",
      " ('class8', 24),\n",
      " ('class10', 6)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(12,7))\n",
    "data1_train, key, value = get_count(dataset1_train_dir)\n",
    "pp.pprint(data1_train)\n",
    "axes.bar(key, value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 500\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dir):\n",
    "  X, y = [], []\n",
    "  labels = os.listdir(dataset_dir)\n",
    "  for label in labels:\n",
    "    file_list = os.listdir(dataset_dir + label + '/')\n",
    "    for f in file_list:\n",
    "      temp = pd.read_csv(dataset_dir + label + '/' + f)\n",
    "      X.append(torch.from_numpy(temp.values))\n",
    "      y.append(label)\n",
    "  X = pad_sequence(X, batch_first=True)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset0's training/test datasets & dataloader\n",
    "dataset0_X_train, dataset0_y_train = create_dataset(dataset0_train_dir)\n",
    "dataset0_y_train = dataset0_label_encoder.transform(dataset0_y_train)\n",
    "\n",
    "dataset0_X_test, dataset0_y_test = create_dataset(dataset0_test_dir)\n",
    "dataset0_y_test = dataset0_label_encoder.transform(dataset0_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24203/2143072385.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset0_train_dataset = TensorDataset(torch.tensor(dataset0_X_train).float(), torch.from_numpy(dataset0_y_train))\n",
      "/tmp/ipykernel_24203/2143072385.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset0_test_dataset = TensorDataset(torch.tensor(dataset0_X_test).float(), torch.from_numpy(dataset0_y_test))\n"
     ]
    }
   ],
   "source": [
    "dataset0_train_dataset = TensorDataset(torch.tensor(dataset0_X_train).float(), torch.from_numpy(dataset0_y_train))\n",
    "dataset0_test_dataset = TensorDataset(torch.tensor(dataset0_X_test).float(), torch.from_numpy(dataset0_y_test))\n",
    "\n",
    "dataset0_train_dataloader = DataLoader(dataset0_train_dataset,\n",
    "                                       sampler=ImbalancedDatasetSampler(dataset0_train_dataset),\n",
    "                                       batch_size=batch_size)\n",
    "dataset0_test_dataloader= DataLoader(dataset0_test_dataset,\n",
    "                                     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24203/3370797675.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset1_train_dataset = TensorDataset(torch.tensor(dataset1_X_train).float(), torch.from_numpy(dataset1_y_train))\n"
     ]
    }
   ],
   "source": [
    "# dataset1's training datasets & dataloader\n",
    "dataset1_X_train, dataset1_y_train = create_dataset(dataset1_train_dir)\n",
    "dataset1_y_train = dataset1_label_encoder.transform(dataset1_y_train)\n",
    "\n",
    "dataset1_train_dataset = TensorDataset(torch.tensor(dataset1_X_train).float(), torch.from_numpy(dataset1_y_train))\n",
    "dataset1_train_dataloader = DataLoader(dataset1_train_dataset,\n",
    "                                       sampler=ImbalancedDatasetSampler(dataset1_train_dataset),\n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "해당 셀의 코드 중 dataloader 부분의 `shuffle=False` 는 수정하면 안됩니다.\n",
    "\"\"\"\n",
    "\n",
    "dataset1_test_X = []\n",
    "test_list = os.listdir(dataset1_test_dir)\n",
    "for f in test_list:\n",
    "  temp = pd.read_csv(dataset1_test_dir + f)\n",
    "  dataset1_test_X.append(torch.from_numpy(temp.values))\n",
    "\n",
    "dataset1_test_X = pad_sequence(dataset1_test_X, batch_first=True)\n",
    "dataset1_test_dataset = TensorDataset(torch.Tensor(dataset1_test_X.float()))\n",
    "dataset1_test_dataloader = DataLoader(dataset1_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "  def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "    super(LSTM1, self).__init__()\n",
    "    self.num_classes = num_classes #number of classes\n",
    "    self.num_layers = num_layers #number of layers\n",
    "    self.input_size = input_size #input size\n",
    "    self.hidden_size = hidden_size #hidden state\n",
    "    self.seq_length = seq_length #sequence length\n",
    " \n",
    "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                      num_layers=num_layers, batch_first=True) #lstm\n",
    "    self.fc_1 =  nn.Linear(hidden_size, 128) \n",
    "    self.fc = nn.Linear(128, num_classes) \n",
    "\n",
    "    self.relu = nn.ReLU() \n",
    "\n",
    "  def forward(self,x):\n",
    "    h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) \n",
    "    c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) \n",
    "\n",
    "    output, (hn, cn) = self.lstm(x, (h_0, c_0)) \n",
    "   \n",
    "    hn = hn.view(-1, self.hidden_size)\n",
    "    out = self.relu(hn)\n",
    "    out = self.fc_1(out) \n",
    "    out = self.relu(out) \n",
    "    out = self.fc(out) \n",
    "   \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class F1_Loss(nn.Module):\n",
    "    def __init__(self, classes, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.classes = classes\n",
    "\n",
    "    def forward(self, y_pred, y_true,):\n",
    "        # assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lr = 0.0001\n",
    "epochs = 1000\n",
    "\n",
    "input_size = 6 #number of features\n",
    "hidden_size = 128 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "num_classes = 15 #number of output classes \n",
    "seq_length = 696\n",
    "lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, seq_length).to(device)\n",
    "\n",
    "# loss_function = torch.nn.MSELoss()  \n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=lr)  # adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, vali_loader, scheduler, device): \n",
    "    model.to(device)\n",
    "    n = len(train_loader)\n",
    "    \n",
    "    # Loss Function\n",
    "    criterion = F1_Loss(classes=15).to(device)\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(1,epochs+1): \n",
    "        model.train() \n",
    "        running_loss = 0.0\n",
    "            \n",
    "        for img, label in iter(train_loader):\n",
    "            img, label = img.to(device), label.to(device) \n",
    "            optimizer.zero_grad() \n",
    "            \n",
    "            logit = model(img) \n",
    "            loss = criterion(logit, label) \n",
    "            \n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "              \n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss / len(train_loader)))\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval() \n",
    "        vali_loss = 0.0\n",
    "        correct = 0\n",
    "        with torch.no_grad(): \n",
    "            for img, label in iter(vali_loader):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "\n",
    "                logit = lstm1(img)\n",
    "                vali_loss += criterion(logit, label)\n",
    "                pred = logit.argmax(dim=1, keepdim=True) \n",
    "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "        vali_acc = 100 * correct / len(vali_loader.dataset)\n",
    "        print('Vail set: Loss: {:.4f}, Accuracy: {}/{} ( {:.0f}%)\\n'.format(vali_loss / len(vali_loader), correct, len(vali_loader.dataset), 100 * correct / len(vali_loader.dataset)))\n",
    "        \n",
    "        if best_acc < vali_acc:\n",
    "            best_acc = vali_acc\n",
    "            torch.save(model.state_dict(), './saved/best_model.pth') \n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 0.9332866268\n",
      "Vail set: Loss: 0.9876, Accuracy: 1863/6975 ( 27%)\n",
      "\n",
      "Model Saved.\n",
      "[2] Train loss: 0.9291009296\n",
      "Vail set: Loss: 0.9852, Accuracy: 1984/6975 ( 28%)\n",
      "\n",
      "Model Saved.\n",
      "[3] Train loss: 0.9151460843\n",
      "Vail set: Loss: 0.9781, Accuracy: 1965/6975 ( 28%)\n",
      "\n",
      "[4] Train loss: 0.8944226937\n",
      "Vail set: Loss: 0.9750, Accuracy: 1935/6975 ( 28%)\n",
      "\n",
      "[5] Train loss: 0.8747851393\n",
      "Vail set: Loss: 0.9737, Accuracy: 2087/6975 ( 30%)\n",
      "\n",
      "Model Saved.\n",
      "[6] Train loss: 0.8535177090\n",
      "Vail set: Loss: 0.9719, Accuracy: 2109/6975 ( 30%)\n",
      "\n",
      "Model Saved.\n",
      "[7] Train loss: 0.8395869212\n",
      "Vail set: Loss: 0.9738, Accuracy: 1922/6975 ( 28%)\n",
      "\n",
      "[8] Train loss: 0.8202931263\n",
      "Vail set: Loss: 0.9696, Accuracy: 2206/6975 ( 32%)\n",
      "\n",
      "Model Saved.\n",
      "[9] Train loss: 0.8036270488\n",
      "Vail set: Loss: 0.9667, Accuracy: 2284/6975 ( 33%)\n",
      "\n",
      "Model Saved.\n",
      "[10] Train loss: 0.7922362729\n",
      "Vail set: Loss: 0.9667, Accuracy: 2454/6975 ( 35%)\n",
      "\n",
      "Model Saved.\n",
      "[11] Train loss: 0.7722094417\n",
      "Vail set: Loss: 0.9640, Accuracy: 2609/6975 ( 37%)\n",
      "\n",
      "Model Saved.\n",
      "[12] Train loss: 0.7643922838\n",
      "Vail set: Loss: 0.9654, Accuracy: 2323/6975 ( 33%)\n",
      "\n",
      "[13] Train loss: 0.7578403245\n",
      "Vail set: Loss: 0.9786, Accuracy: 882/6975 ( 13%)\n",
      "\n",
      "[14] Train loss: 0.7970315446\n",
      "Vail set: Loss: 0.9739, Accuracy: 1433/6975 ( 21%)\n",
      "\n",
      "[15] Train loss: 0.7681748737\n",
      "Vail set: Loss: 0.9657, Accuracy: 2142/6975 ( 31%)\n",
      "\n",
      "[16] Train loss: 0.7572531072\n",
      "Vail set: Loss: 0.9641, Accuracy: 2297/6975 ( 33%)\n",
      "\n",
      "[17] Train loss: 0.7433071873\n",
      "Vail set: Loss: 0.9623, Accuracy: 2448/6975 ( 35%)\n",
      "\n",
      "[18] Train loss: 0.7349456917\n",
      "Vail set: Loss: 0.9613, Accuracy: 2378/6975 ( 34%)\n",
      "\n",
      "[19] Train loss: 0.7216891018\n",
      "Vail set: Loss: 0.9601, Accuracy: 2537/6975 ( 36%)\n",
      "\n",
      "[20] Train loss: 0.7396216859\n",
      "Vail set: Loss: 0.9614, Accuracy: 2542/6975 ( 36%)\n",
      "\n",
      "[21] Train loss: 0.7344138037\n",
      "Vail set: Loss: 0.9597, Accuracy: 2631/6975 ( 38%)\n",
      "\n",
      "Model Saved.\n",
      "[22] Train loss: 0.7348234762\n",
      "Vail set: Loss: 0.9603, Accuracy: 2530/6975 ( 36%)\n",
      "\n",
      "[23] Train loss: 0.7131320769\n",
      "Vail set: Loss: 0.9615, Accuracy: 2280/6975 ( 33%)\n",
      "\n",
      "[24] Train loss: 0.7180672440\n",
      "Vail set: Loss: 0.9607, Accuracy: 2407/6975 ( 35%)\n",
      "\n",
      "[25] Train loss: 0.7056612112\n",
      "Vail set: Loss: 0.9598, Accuracy: 2425/6975 ( 35%)\n",
      "\n",
      "[26] Train loss: 0.6913383766\n",
      "Vail set: Loss: 0.9591, Accuracy: 2479/6975 ( 36%)\n",
      "\n",
      "[27] Train loss: 0.6877741879\n",
      "Vail set: Loss: 0.9570, Accuracy: 2557/6975 ( 37%)\n",
      "\n",
      "[28] Train loss: 0.6803673257\n",
      "Vail set: Loss: 0.9557, Accuracy: 2720/6975 ( 39%)\n",
      "\n",
      "Model Saved.\n",
      "[29] Train loss: 0.6746022203\n",
      "Vail set: Loss: 0.9547, Accuracy: 2917/6975 ( 42%)\n",
      "\n",
      "Model Saved.\n",
      "[30] Train loss: 0.6738365867\n",
      "Vail set: Loss: 0.9524, Accuracy: 3105/6975 ( 45%)\n",
      "\n",
      "Model Saved.\n",
      "[31] Train loss: 0.6634020068\n",
      "Vail set: Loss: 0.9523, Accuracy: 3143/6975 ( 45%)\n",
      "\n",
      "Model Saved.\n",
      "[32] Train loss: 0.6650639783\n",
      "Vail set: Loss: 0.9514, Accuracy: 3160/6975 ( 45%)\n",
      "\n",
      "Model Saved.\n",
      "[33] Train loss: 0.6596906651\n",
      "Vail set: Loss: 0.9517, Accuracy: 3107/6975 ( 45%)\n",
      "\n",
      "[34] Train loss: 0.6591663762\n",
      "Vail set: Loss: 0.9506, Accuracy: 3196/6975 ( 46%)\n",
      "\n",
      "Model Saved.\n",
      "[35] Train loss: 0.6589927337\n",
      "Vail set: Loss: 0.9543, Accuracy: 2847/6975 ( 41%)\n",
      "\n",
      "[36] Train loss: 0.6613252174\n",
      "Vail set: Loss: 0.9505, Accuracy: 3226/6975 ( 46%)\n",
      "\n",
      "Model Saved.\n",
      "[37] Train loss: 0.6497944052\n",
      "Vail set: Loss: 0.9503, Accuracy: 3186/6975 ( 46%)\n",
      "\n",
      "[38] Train loss: 0.6450174364\n",
      "Vail set: Loss: 0.9498, Accuracy: 3200/6975 ( 46%)\n",
      "\n",
      "[39] Train loss: 0.6450399507\n",
      "Vail set: Loss: 0.9497, Accuracy: 3195/6975 ( 46%)\n",
      "\n",
      "[40] Train loss: 0.6421371709\n",
      "Vail set: Loss: 0.9490, Accuracy: 3197/6975 ( 46%)\n",
      "\n",
      "[41] Train loss: 0.6381786661\n",
      "Vail set: Loss: 0.9492, Accuracy: 3228/6975 ( 46%)\n",
      "\n",
      "Model Saved.\n",
      "[42] Train loss: 0.6334924969\n",
      "Vail set: Loss: 0.9488, Accuracy: 3285/6975 ( 47%)\n",
      "\n",
      "Model Saved.\n",
      "[43] Train loss: 0.6705498804\n",
      "Vail set: Loss: 0.9529, Accuracy: 2857/6975 ( 41%)\n",
      "\n",
      "[44] Train loss: 0.6894616745\n",
      "Vail set: Loss: 0.9514, Accuracy: 2998/6975 ( 43%)\n",
      "\n",
      "[45] Train loss: 0.6784642360\n",
      "Vail set: Loss: 0.9508, Accuracy: 3102/6975 ( 44%)\n",
      "\n",
      "[46] Train loss: 0.6770427921\n",
      "Vail set: Loss: 0.9496, Accuracy: 3237/6975 ( 46%)\n",
      "\n",
      "[47] Train loss: 0.7277382591\n",
      "Vail set: Loss: 0.9790, Accuracy: 941/6975 ( 13%)\n",
      "\n",
      "[48] Train loss: 0.8088993473\n",
      "Vail set: Loss: 0.9779, Accuracy: 961/6975 ( 14%)\n",
      "\n",
      "[49] Train loss: 0.7925139091\n",
      "Vail set: Loss: 0.9767, Accuracy: 1076/6975 ( 15%)\n",
      "\n",
      "[50] Train loss: 0.7816253749\n",
      "Vail set: Loss: 0.9762, Accuracy: 1093/6975 ( 16%)\n",
      "\n",
      "[51] Train loss: 0.7745904933\n",
      "Vail set: Loss: 0.9759, Accuracy: 1087/6975 ( 16%)\n",
      "\n",
      "[52] Train loss: 0.7586544860\n",
      "Vail set: Loss: 0.9758, Accuracy: 1086/6975 ( 16%)\n",
      "\n",
      "[53] Train loss: 0.7528998819\n",
      "Vail set: Loss: 0.9754, Accuracy: 1110/6975 ( 16%)\n",
      "\n",
      "[54] Train loss: 0.7492597255\n",
      "Vail set: Loss: 0.9747, Accuracy: 1174/6975 ( 17%)\n",
      "\n",
      "[55] Train loss: 0.7378097556\n",
      "Vail set: Loss: 0.9728, Accuracy: 1237/6975 ( 18%)\n",
      "\n",
      "[56] Train loss: 0.7318492142\n",
      "Vail set: Loss: 0.9665, Accuracy: 1737/6975 ( 25%)\n",
      "\n",
      "[57] Train loss: 0.7188640183\n",
      "Vail set: Loss: 0.9645, Accuracy: 2004/6975 ( 29%)\n",
      "\n",
      "[58] Train loss: 0.7276926420\n",
      "Vail set: Loss: 0.9646, Accuracy: 2036/6975 ( 29%)\n",
      "\n",
      "[59] Train loss: 0.7117879900\n",
      "Vail set: Loss: 0.9635, Accuracy: 2146/6975 ( 31%)\n",
      "\n",
      "[60] Train loss: 0.7023578340\n",
      "Vail set: Loss: 0.9623, Accuracy: 2263/6975 ( 32%)\n",
      "\n",
      "[61] Train loss: 0.6939221631\n",
      "Vail set: Loss: 0.9614, Accuracy: 2392/6975 ( 34%)\n",
      "\n",
      "[62] Train loss: 0.6884901003\n",
      "Vail set: Loss: 0.9611, Accuracy: 2430/6975 ( 35%)\n",
      "\n",
      "[63] Train loss: 0.6947510708\n",
      "Vail set: Loss: 0.9601, Accuracy: 2404/6975 ( 34%)\n",
      "\n",
      "[64] Train loss: 0.6831632311\n",
      "Vail set: Loss: 0.9592, Accuracy: 2468/6975 ( 35%)\n",
      "\n",
      "[65] Train loss: 0.6639865301\n",
      "Vail set: Loss: 0.9506, Accuracy: 3166/6975 ( 45%)\n",
      "\n",
      "[66] Train loss: 0.6380157991\n",
      "Vail set: Loss: 0.9476, Accuracy: 3420/6975 ( 49%)\n",
      "\n",
      "Model Saved.\n",
      "[67] Train loss: 0.6190663479\n",
      "Vail set: Loss: 0.9462, Accuracy: 3568/6975 ( 51%)\n",
      "\n",
      "Model Saved.\n",
      "[68] Train loss: 0.6066550764\n",
      "Vail set: Loss: 0.9462, Accuracy: 3415/6975 ( 49%)\n",
      "\n",
      "[69] Train loss: 0.6018322804\n",
      "Vail set: Loss: 0.9445, Accuracy: 3698/6975 ( 53%)\n",
      "\n",
      "Model Saved.\n",
      "[70] Train loss: 0.6008841937\n",
      "Vail set: Loss: 0.9455, Accuracy: 3561/6975 ( 51%)\n",
      "\n",
      "[71] Train loss: 0.5913887176\n",
      "Vail set: Loss: 0.9457, Accuracy: 3466/6975 ( 50%)\n",
      "\n",
      "[72] Train loss: 0.5961203738\n",
      "Vail set: Loss: 0.9455, Accuracy: 3518/6975 ( 50%)\n",
      "\n",
      "[73] Train loss: 0.5949333939\n",
      "Vail set: Loss: 0.9446, Accuracy: 3506/6975 ( 50%)\n",
      "\n",
      "[74] Train loss: 0.5954063004\n",
      "Vail set: Loss: 0.9440, Accuracy: 3599/6975 ( 52%)\n",
      "\n",
      "[75] Train loss: 0.5915657780\n",
      "Vail set: Loss: 0.9427, Accuracy: 3843/6975 ( 55%)\n",
      "\n",
      "Model Saved.\n",
      "[76] Train loss: 0.5874246391\n",
      "Vail set: Loss: 0.9442, Accuracy: 3687/6975 ( 53%)\n",
      "\n",
      "[77] Train loss: 0.5836772778\n",
      "Vail set: Loss: 0.9440, Accuracy: 3746/6975 ( 54%)\n",
      "\n",
      "[78] Train loss: 0.5804085309\n",
      "Vail set: Loss: 0.9559, Accuracy: 2496/6975 ( 36%)\n",
      "\n",
      "[79] Train loss: 0.5992824088\n",
      "Vail set: Loss: 0.9449, Accuracy: 3609/6975 ( 52%)\n",
      "\n",
      "[80] Train loss: 0.5751387022\n",
      "Vail set: Loss: 0.9451, Accuracy: 3491/6975 ( 50%)\n",
      "\n",
      "[81] Train loss: 0.5912859516\n",
      "Vail set: Loss: 0.9472, Accuracy: 3168/6975 ( 45%)\n",
      "\n",
      "[82] Train loss: 0.6033448469\n",
      "Vail set: Loss: 0.9411, Accuracy: 3923/6975 ( 56%)\n",
      "\n",
      "Model Saved.\n",
      "[83] Train loss: 0.5991773367\n",
      "Vail set: Loss: 0.9442, Accuracy: 3710/6975 ( 53%)\n",
      "\n",
      "[84] Train loss: 0.6103943987\n",
      "Vail set: Loss: 0.9442, Accuracy: 3789/6975 ( 54%)\n",
      "\n",
      "[85] Train loss: 0.6318826437\n",
      "Vail set: Loss: 0.9440, Accuracy: 3802/6975 ( 55%)\n",
      "\n",
      "[86] Train loss: 0.6049043157\n",
      "Vail set: Loss: 0.9432, Accuracy: 3902/6975 ( 56%)\n",
      "\n",
      "[87] Train loss: 0.6092444572\n",
      "Vail set: Loss: 0.9444, Accuracy: 3789/6975 ( 54%)\n",
      "\n",
      "[88] Train loss: 0.5919362708\n",
      "Vail set: Loss: 0.9439, Accuracy: 3775/6975 ( 54%)\n",
      "\n",
      "[89] Train loss: 0.5927481857\n",
      "Vail set: Loss: 0.9458, Accuracy: 3515/6975 ( 50%)\n",
      "\n",
      "[90] Train loss: 0.5959522388\n",
      "Vail set: Loss: 0.9439, Accuracy: 3670/6975 ( 53%)\n",
      "\n",
      "[91] Train loss: 0.5803328460\n",
      "Vail set: Loss: 0.9435, Accuracy: 3670/6975 ( 53%)\n",
      "\n",
      "[92] Train loss: 0.5880959782\n",
      "Vail set: Loss: 0.9441, Accuracy: 3585/6975 ( 51%)\n",
      "\n",
      "[93] Train loss: 0.5835110675\n",
      "Vail set: Loss: 0.9462, Accuracy: 3338/6975 ( 48%)\n",
      "\n",
      "[94] Train loss: 0.5741493594\n",
      "Vail set: Loss: 0.9441, Accuracy: 3647/6975 ( 52%)\n",
      "\n",
      "[95] Train loss: 0.5682085352\n",
      "Vail set: Loss: 0.9432, Accuracy: 3721/6975 ( 53%)\n",
      "\n",
      "[96] Train loss: 0.5911392060\n",
      "Vail set: Loss: 0.9417, Accuracy: 3934/6975 ( 56%)\n",
      "\n",
      "Model Saved.\n",
      "[97] Train loss: 0.5705021240\n",
      "Vail set: Loss: 0.9426, Accuracy: 3774/6975 ( 54%)\n",
      "\n",
      "[98] Train loss: 0.5684101213\n",
      "Vail set: Loss: 0.9431, Accuracy: 3762/6975 ( 54%)\n",
      "\n",
      "[99] Train loss: 0.5787893425\n",
      "Vail set: Loss: 0.9414, Accuracy: 4047/6975 ( 58%)\n",
      "\n",
      "Model Saved.\n",
      "[100] Train loss: 0.5857609901\n",
      "Vail set: Loss: 0.9399, Accuracy: 4147/6975 ( 59%)\n",
      "\n",
      "Model Saved.\n",
      "[101] Train loss: 0.5652364319\n",
      "Vail set: Loss: 0.9402, Accuracy: 4077/6975 ( 58%)\n",
      "\n",
      "[102] Train loss: 0.5780414982\n",
      "Vail set: Loss: 0.9398, Accuracy: 4153/6975 ( 60%)\n",
      "\n",
      "Model Saved.\n",
      "[103] Train loss: 0.5833885247\n",
      "Vail set: Loss: 0.9416, Accuracy: 4057/6975 ( 58%)\n",
      "\n",
      "[104] Train loss: 0.5600476807\n",
      "Vail set: Loss: 0.9413, Accuracy: 3937/6975 ( 56%)\n",
      "\n",
      "[105] Train loss: 0.5630676421\n",
      "Vail set: Loss: 0.9413, Accuracy: 3910/6975 ( 56%)\n",
      "\n",
      "[106] Train loss: 0.5570901686\n",
      "Vail set: Loss: 0.9411, Accuracy: 3960/6975 ( 57%)\n",
      "\n",
      "[107] Train loss: 0.5494858709\n",
      "Vail set: Loss: 0.9409, Accuracy: 3847/6975 ( 55%)\n",
      "\n",
      "[108] Train loss: 0.5341136791\n",
      "Vail set: Loss: 0.9402, Accuracy: 4009/6975 ( 57%)\n",
      "\n",
      "[109] Train loss: 0.5341764017\n",
      "Vail set: Loss: 0.9394, Accuracy: 4095/6975 ( 59%)\n",
      "\n",
      "[110] Train loss: 0.5292214708\n",
      "Vail set: Loss: 0.9399, Accuracy: 4030/6975 ( 58%)\n",
      "\n",
      "[111] Train loss: 0.5292513089\n",
      "Vail set: Loss: 0.9394, Accuracy: 4041/6975 ( 58%)\n",
      "\n",
      "[112] Train loss: 0.5336046208\n",
      "Vail set: Loss: 0.9390, Accuracy: 4110/6975 ( 59%)\n",
      "\n",
      "[113] Train loss: 0.5277584379\n",
      "Vail set: Loss: 0.9404, Accuracy: 3971/6975 ( 57%)\n",
      "\n",
      "[114] Train loss: 0.5283940424\n",
      "Vail set: Loss: 0.9392, Accuracy: 4021/6975 ( 58%)\n",
      "\n",
      "[115] Train loss: 0.5227495475\n",
      "Vail set: Loss: 0.9386, Accuracy: 4114/6975 ( 59%)\n",
      "\n",
      "[116] Train loss: 0.5224798441\n",
      "Vail set: Loss: 0.9387, Accuracy: 4114/6975 ( 59%)\n",
      "\n",
      "[117] Train loss: 0.5159258496\n",
      "Vail set: Loss: 0.9379, Accuracy: 4209/6975 ( 60%)\n",
      "\n",
      "Model Saved.\n",
      "[118] Train loss: 0.5136785366\n",
      "Vail set: Loss: 0.9387, Accuracy: 4012/6975 ( 58%)\n",
      "\n",
      "[119] Train loss: 0.5192288063\n",
      "Vail set: Loss: 0.9384, Accuracy: 4154/6975 ( 60%)\n",
      "\n",
      "[120] Train loss: 0.5243103103\n",
      "Vail set: Loss: 0.9376, Accuracy: 4142/6975 ( 59%)\n",
      "\n",
      "[121] Train loss: 0.5166316108\n",
      "Vail set: Loss: 0.9375, Accuracy: 4230/6975 ( 61%)\n",
      "\n",
      "Model Saved.\n",
      "[122] Train loss: 0.5101048339\n",
      "Vail set: Loss: 0.9378, Accuracy: 4213/6975 ( 60%)\n",
      "\n",
      "[123] Train loss: 0.6761148789\n",
      "Vail set: Loss: 0.9606, Accuracy: 2080/6975 ( 30%)\n",
      "\n",
      "[124] Train loss: 0.6497406255\n",
      "Vail set: Loss: 0.9456, Accuracy: 3466/6975 ( 50%)\n",
      "\n",
      "[125] Train loss: 0.5906774889\n",
      "Vail set: Loss: 0.9413, Accuracy: 3897/6975 ( 56%)\n",
      "\n",
      "[126] Train loss: 0.5570747787\n",
      "Vail set: Loss: 0.9409, Accuracy: 3908/6975 ( 56%)\n",
      "\n",
      "[127] Train loss: 0.5368290078\n",
      "Vail set: Loss: 0.9388, Accuracy: 4096/6975 ( 59%)\n",
      "\n",
      "[128] Train loss: 0.5307844617\n",
      "Vail set: Loss: 0.9383, Accuracy: 4145/6975 ( 59%)\n",
      "\n",
      "[129] Train loss: 0.5204925331\n",
      "Vail set: Loss: 0.9381, Accuracy: 4173/6975 ( 60%)\n",
      "\n",
      "[130] Train loss: 0.5249315392\n",
      "Vail set: Loss: 0.9381, Accuracy: 4171/6975 ( 60%)\n",
      "\n",
      "[131] Train loss: 0.5291010867\n",
      "Vail set: Loss: 0.9391, Accuracy: 4085/6975 ( 59%)\n",
      "\n",
      "[132] Train loss: 0.5292837197\n",
      "Vail set: Loss: 0.9382, Accuracy: 4177/6975 ( 60%)\n",
      "\n",
      "[133] Train loss: 0.5237581903\n",
      "Vail set: Loss: 0.9383, Accuracy: 4184/6975 ( 60%)\n",
      "\n",
      "[134] Train loss: 0.5179121028\n",
      "Vail set: Loss: 0.9381, Accuracy: 4135/6975 ( 59%)\n",
      "\n",
      "[135] Train loss: 0.5116738688\n",
      "Vail set: Loss: 0.9375, Accuracy: 4206/6975 ( 60%)\n",
      "\n",
      "[136] Train loss: 0.5123410593\n",
      "Vail set: Loss: 0.9373, Accuracy: 4176/6975 ( 60%)\n",
      "\n",
      "[137] Train loss: 0.5080671906\n",
      "Vail set: Loss: 0.9379, Accuracy: 4126/6975 ( 59%)\n",
      "\n",
      "[138] Train loss: 0.5020513795\n",
      "Vail set: Loss: 0.9368, Accuracy: 4238/6975 ( 61%)\n",
      "\n",
      "Model Saved.\n",
      "[139] Train loss: 0.4972631064\n",
      "Vail set: Loss: 0.9373, Accuracy: 4204/6975 ( 60%)\n",
      "\n",
      "[140] Train loss: 0.4982392593\n",
      "Vail set: Loss: 0.9367, Accuracy: 4252/6975 ( 61%)\n",
      "\n",
      "Model Saved.\n",
      "[141] Train loss: 0.5041555751\n",
      "Vail set: Loss: 0.9371, Accuracy: 4183/6975 ( 60%)\n",
      "\n",
      "[142] Train loss: 0.5089279652\n",
      "Vail set: Loss: 0.9372, Accuracy: 4131/6975 ( 59%)\n",
      "\n",
      "[143] Train loss: 0.4992907795\n",
      "Vail set: Loss: 0.9364, Accuracy: 4272/6975 ( 61%)\n",
      "\n",
      "Model Saved.\n",
      "[144] Train loss: 0.5042115710\n",
      "Vail set: Loss: 0.9371, Accuracy: 4217/6975 ( 60%)\n",
      "\n",
      "[145] Train loss: 0.4968517618\n",
      "Vail set: Loss: 0.9367, Accuracy: 4254/6975 ( 61%)\n",
      "\n",
      "[146] Train loss: 0.4987826770\n",
      "Vail set: Loss: 0.9367, Accuracy: 4177/6975 ( 60%)\n",
      "\n",
      "[147] Train loss: 0.5023774721\n",
      "Vail set: Loss: 0.9364, Accuracy: 4277/6975 ( 61%)\n",
      "\n",
      "Model Saved.\n",
      "[148] Train loss: 0.5017424692\n",
      "Vail set: Loss: 0.9363, Accuracy: 4262/6975 ( 61%)\n",
      "\n",
      "[149] Train loss: 0.4942394322\n",
      "Vail set: Loss: 0.9366, Accuracy: 4250/6975 ( 61%)\n",
      "\n",
      "[150] Train loss: 0.4939924663\n",
      "Vail set: Loss: 0.9362, Accuracy: 4269/6975 ( 61%)\n",
      "\n",
      "[151] Train loss: 0.5037411928\n",
      "Vail set: Loss: 0.9366, Accuracy: 4229/6975 ( 61%)\n",
      "\n",
      "[152] Train loss: 0.5033018914\n",
      "Vail set: Loss: 0.9371, Accuracy: 4142/6975 ( 59%)\n",
      "\n",
      "[153] Train loss: 0.4955991181\n",
      "Vail set: Loss: 0.9360, Accuracy: 4306/6975 ( 62%)\n",
      "\n",
      "Model Saved.\n",
      "[154] Train loss: 0.5181902875\n",
      "Vail set: Loss: 0.9368, Accuracy: 4217/6975 ( 60%)\n",
      "\n",
      "[155] Train loss: 0.4984637661\n",
      "Vail set: Loss: 0.9361, Accuracy: 4298/6975 ( 62%)\n",
      "\n",
      "[156] Train loss: 0.4946488435\n",
      "Vail set: Loss: 0.9367, Accuracy: 4222/6975 ( 61%)\n",
      "\n",
      "[157] Train loss: 0.4941853339\n",
      "Vail set: Loss: 0.9369, Accuracy: 4127/6975 ( 59%)\n",
      "\n",
      "[158] Train loss: 0.4968112176\n",
      "Vail set: Loss: 0.9365, Accuracy: 4252/6975 ( 61%)\n",
      "\n",
      "[159] Train loss: 0.5073622769\n",
      "Vail set: Loss: 0.9371, Accuracy: 4205/6975 ( 60%)\n",
      "\n",
      "[160] Train loss: 0.4934959401\n",
      "Vail set: Loss: 0.9365, Accuracy: 4248/6975 ( 61%)\n",
      "\n",
      "[161] Train loss: 0.4870075248\n",
      "Vail set: Loss: 0.9361, Accuracy: 4284/6975 ( 61%)\n",
      "\n",
      "[162] Train loss: 0.4973200733\n",
      "Vail set: Loss: 0.9370, Accuracy: 4135/6975 ( 59%)\n",
      "\n",
      "[163] Train loss: 0.5915611581\n",
      "Vail set: Loss: 0.9494, Accuracy: 3339/6975 ( 48%)\n",
      "\n",
      "[164] Train loss: 0.6318010970\n",
      "Vail set: Loss: 0.9453, Accuracy: 3582/6975 ( 51%)\n",
      "\n",
      "[165] Train loss: 0.5636676268\n",
      "Vail set: Loss: 0.9411, Accuracy: 3885/6975 ( 56%)\n",
      "\n",
      "[166] Train loss: 0.5346463659\n",
      "Vail set: Loss: 0.9375, Accuracy: 4175/6975 ( 60%)\n",
      "\n",
      "[167] Train loss: 0.5010465416\n",
      "Vail set: Loss: 0.9365, Accuracy: 4239/6975 ( 61%)\n",
      "\n",
      "[168] Train loss: 0.5127376134\n",
      "Vail set: Loss: 0.9366, Accuracy: 4178/6975 ( 60%)\n",
      "\n",
      "[169] Train loss: 0.5009579323\n",
      "Vail set: Loss: 0.9365, Accuracy: 4274/6975 ( 61%)\n",
      "\n",
      "[170] Train loss: 0.4894415281\n",
      "Vail set: Loss: 0.9366, Accuracy: 4244/6975 ( 61%)\n",
      "\n",
      "[171] Train loss: 0.5224229368\n",
      "Vail set: Loss: 0.9396, Accuracy: 3908/6975 ( 56%)\n",
      "\n",
      "[172] Train loss: 0.5043658072\n",
      "Vail set: Loss: 0.9374, Accuracy: 4173/6975 ( 60%)\n",
      "\n",
      "[173] Train loss: 0.5038507819\n",
      "Vail set: Loss: 0.9362, Accuracy: 4315/6975 ( 62%)\n",
      "\n",
      "Model Saved.\n",
      "[174] Train loss: 0.4886385062\n",
      "Vail set: Loss: 0.9351, Accuracy: 4353/6975 ( 62%)\n",
      "\n",
      "Model Saved.\n",
      "[175] Train loss: 0.4853809053\n",
      "Vail set: Loss: 0.9367, Accuracy: 4162/6975 ( 60%)\n",
      "\n",
      "[176] Train loss: 0.4956116243\n",
      "Vail set: Loss: 0.9353, Accuracy: 4324/6975 ( 62%)\n",
      "\n",
      "[177] Train loss: 0.4924205693\n",
      "Vail set: Loss: 0.9352, Accuracy: 4339/6975 ( 62%)\n",
      "\n",
      "[178] Train loss: 0.4840299910\n",
      "Vail set: Loss: 0.9383, Accuracy: 3992/6975 ( 57%)\n",
      "\n",
      "[179] Train loss: 0.4904689269\n",
      "Vail set: Loss: 0.9365, Accuracy: 4153/6975 ( 60%)\n",
      "\n",
      "[180] Train loss: 0.4794335831\n",
      "Vail set: Loss: 0.9354, Accuracy: 4371/6975 ( 63%)\n",
      "\n",
      "Model Saved.\n",
      "[181] Train loss: 0.4871954669\n",
      "Vail set: Loss: 0.9359, Accuracy: 4241/6975 ( 61%)\n",
      "\n",
      "[182] Train loss: 0.4920113358\n",
      "Vail set: Loss: 0.9355, Accuracy: 4373/6975 ( 63%)\n",
      "\n",
      "Model Saved.\n",
      "[183] Train loss: 0.4809707761\n",
      "Vail set: Loss: 0.9353, Accuracy: 4421/6975 ( 63%)\n",
      "\n",
      "Model Saved.\n",
      "[184] Train loss: 0.4746922699\n",
      "Vail set: Loss: 0.9363, Accuracy: 4214/6975 ( 60%)\n",
      "\n",
      "[185] Train loss: 0.4783227715\n",
      "Vail set: Loss: 0.9351, Accuracy: 4309/6975 ( 62%)\n",
      "\n",
      "[186] Train loss: 0.4845166434\n",
      "Vail set: Loss: 0.9353, Accuracy: 4409/6975 ( 63%)\n",
      "\n",
      "[187] Train loss: 0.4830128420\n",
      "Vail set: Loss: 0.9377, Accuracy: 4052/6975 ( 58%)\n",
      "\n",
      "[188] Train loss: 0.4793358662\n",
      "Vail set: Loss: 0.9353, Accuracy: 4412/6975 ( 63%)\n",
      "\n",
      "[189] Train loss: 0.4917086634\n",
      "Vail set: Loss: 0.9349, Accuracy: 4432/6975 ( 64%)\n",
      "\n",
      "Model Saved.\n",
      "[190] Train loss: 0.4769223527\n",
      "Vail set: Loss: 0.9347, Accuracy: 4450/6975 ( 64%)\n",
      "\n",
      "Model Saved.\n",
      "[191] Train loss: 0.4943652511\n",
      "Vail set: Loss: 0.9366, Accuracy: 4282/6975 ( 61%)\n",
      "\n",
      "[192] Train loss: 0.4825851733\n",
      "Vail set: Loss: 0.9350, Accuracy: 4381/6975 ( 63%)\n",
      "\n",
      "[193] Train loss: 0.4818491101\n",
      "Vail set: Loss: 0.9354, Accuracy: 4283/6975 ( 61%)\n",
      "\n",
      "[194] Train loss: 0.4713903904\n",
      "Vail set: Loss: 0.9361, Accuracy: 4213/6975 ( 60%)\n",
      "\n",
      "[195] Train loss: 0.4828584140\n",
      "Vail set: Loss: 0.9444, Accuracy: 3413/6975 ( 49%)\n",
      "\n",
      "[196] Train loss: 0.4908782829\n",
      "Vail set: Loss: 0.9355, Accuracy: 4269/6975 ( 61%)\n",
      "\n",
      "[197] Train loss: 0.4660815250\n",
      "Vail set: Loss: 0.9350, Accuracy: 4354/6975 ( 62%)\n",
      "\n",
      "[198] Train loss: 0.4750486732\n",
      "Vail set: Loss: 0.9346, Accuracy: 4395/6975 ( 63%)\n",
      "\n",
      "[199] Train loss: 0.4703934106\n",
      "Vail set: Loss: 0.9346, Accuracy: 4374/6975 ( 63%)\n",
      "\n",
      "[200] Train loss: 0.4609067234\n",
      "Vail set: Loss: 0.9349, Accuracy: 4312/6975 ( 62%)\n",
      "\n",
      "[201] Train loss: 0.4650318872\n",
      "Vail set: Loss: 0.9346, Accuracy: 4395/6975 ( 63%)\n",
      "\n",
      "[202] Train loss: 0.4624128385\n",
      "Vail set: Loss: 0.9350, Accuracy: 4362/6975 ( 63%)\n",
      "\n",
      "[203] Train loss: 0.4768916477\n",
      "Vail set: Loss: 0.9348, Accuracy: 4353/6975 ( 62%)\n",
      "\n",
      "[204] Train loss: 0.4661095944\n",
      "Vail set: Loss: 0.9365, Accuracy: 4176/6975 ( 60%)\n",
      "\n",
      "[205] Train loss: 0.4777295329\n",
      "Vail set: Loss: 0.9347, Accuracy: 4397/6975 ( 63%)\n",
      "\n",
      "[206] Train loss: 0.4773146792\n",
      "Vail set: Loss: 0.9352, Accuracy: 4343/6975 ( 62%)\n",
      "\n",
      "[207] Train loss: 0.4628414057\n",
      "Vail set: Loss: 0.9342, Accuracy: 4444/6975 ( 64%)\n",
      "\n",
      "[208] Train loss: 0.4627218311\n",
      "Vail set: Loss: 0.9347, Accuracy: 4390/6975 ( 63%)\n",
      "\n",
      "[209] Train loss: 0.4605562611\n",
      "Vail set: Loss: 0.9344, Accuracy: 4406/6975 ( 63%)\n",
      "\n",
      "[210] Train loss: 0.4690506664\n",
      "Vail set: Loss: 0.9346, Accuracy: 4391/6975 ( 63%)\n",
      "\n",
      "[211] Train loss: 0.4691323410\n",
      "Vail set: Loss: 0.9356, Accuracy: 4282/6975 ( 61%)\n",
      "\n",
      "[212] Train loss: 0.5012209871\n",
      "Vail set: Loss: 0.9350, Accuracy: 4322/6975 ( 62%)\n",
      "\n",
      "[213] Train loss: 0.4892400579\n",
      "Vail set: Loss: 0.9349, Accuracy: 4364/6975 ( 63%)\n",
      "\n",
      "[214] Train loss: 0.4965509165\n",
      "Vail set: Loss: 0.9343, Accuracy: 4439/6975 ( 64%)\n",
      "\n",
      "[215] Train loss: 0.4846655087\n",
      "Vail set: Loss: 0.9345, Accuracy: 4396/6975 ( 63%)\n",
      "\n",
      "[216] Train loss: 0.4922932289\n",
      "Vail set: Loss: 0.9338, Accuracy: 4517/6975 ( 65%)\n",
      "\n",
      "Model Saved.\n",
      "[217] Train loss: 0.4925349431\n",
      "Vail set: Loss: 0.9348, Accuracy: 4388/6975 ( 63%)\n",
      "\n",
      "[218] Train loss: 0.4967331063\n",
      "Vail set: Loss: 0.9348, Accuracy: 4340/6975 ( 62%)\n",
      "\n",
      "[219] Train loss: 0.5031122858\n",
      "Vail set: Loss: 0.9349, Accuracy: 4398/6975 ( 63%)\n",
      "\n",
      "[220] Train loss: 0.4879502827\n",
      "Vail set: Loss: 0.9342, Accuracy: 4436/6975 ( 64%)\n",
      "\n",
      "[221] Train loss: 0.5016222845\n",
      "Vail set: Loss: 0.9350, Accuracy: 4343/6975 ( 62%)\n",
      "\n",
      "[222] Train loss: 0.4896882187\n",
      "Vail set: Loss: 0.9355, Accuracy: 4270/6975 ( 61%)\n",
      "\n",
      "[223] Train loss: 0.4909249360\n",
      "Vail set: Loss: 0.9341, Accuracy: 4471/6975 ( 64%)\n",
      "\n",
      "[224] Train loss: 0.4953251297\n",
      "Vail set: Loss: 0.9344, Accuracy: 4456/6975 ( 64%)\n",
      "\n",
      "[225] Train loss: 0.4928449696\n",
      "Vail set: Loss: 0.9360, Accuracy: 4198/6975 ( 60%)\n",
      "\n",
      "[226] Train loss: 0.4882017407\n",
      "Vail set: Loss: 0.9346, Accuracy: 4359/6975 ( 62%)\n",
      "\n",
      "[227] Train loss: 0.4924904000\n",
      "Vail set: Loss: 0.9351, Accuracy: 4247/6975 ( 61%)\n",
      "\n",
      "[228] Train loss: 0.4927800439\n",
      "Vail set: Loss: 0.9339, Accuracy: 4431/6975 ( 64%)\n",
      "\n",
      "[229] Train loss: 0.4940712376\n",
      "Vail set: Loss: 0.9353, Accuracy: 4272/6975 ( 61%)\n",
      "\n",
      "[230] Train loss: 0.4837908322\n",
      "Vail set: Loss: 0.9345, Accuracy: 4378/6975 ( 63%)\n",
      "\n",
      "[231] Train loss: 0.4691278122\n",
      "Vail set: Loss: 0.9346, Accuracy: 4356/6975 ( 62%)\n",
      "\n",
      "[232] Train loss: 0.4655779373\n",
      "Vail set: Loss: 0.9348, Accuracy: 4300/6975 ( 62%)\n",
      "\n",
      "[233] Train loss: 0.4679250641\n",
      "Vail set: Loss: 0.9347, Accuracy: 4331/6975 ( 62%)\n",
      "\n",
      "[234] Train loss: 0.4726514101\n",
      "Vail set: Loss: 0.9345, Accuracy: 4337/6975 ( 62%)\n",
      "\n",
      "[235] Train loss: 0.4541193485\n",
      "Vail set: Loss: 0.9345, Accuracy: 4382/6975 ( 63%)\n",
      "\n",
      "[236] Train loss: 0.4589484377\n",
      "Vail set: Loss: 0.9353, Accuracy: 4261/6975 ( 61%)\n",
      "\n",
      "[237] Train loss: 0.4579308261\n",
      "Vail set: Loss: 0.9338, Accuracy: 4452/6975 ( 64%)\n",
      "\n",
      "[238] Train loss: 0.4768892700\n",
      "Vail set: Loss: 0.9335, Accuracy: 4472/6975 ( 64%)\n",
      "\n",
      "[239] Train loss: 0.4661051729\n",
      "Vail set: Loss: 0.9337, Accuracy: 4449/6975 ( 64%)\n",
      "\n",
      "[240] Train loss: 0.4746068944\n",
      "Vail set: Loss: 0.9339, Accuracy: 4421/6975 ( 63%)\n",
      "\n",
      "[241] Train loss: 0.4631432392\n",
      "Vail set: Loss: 0.9330, Accuracy: 4487/6975 ( 64%)\n",
      "\n",
      "[242] Train loss: 0.4582056468\n",
      "Vail set: Loss: 0.9339, Accuracy: 4358/6975 ( 62%)\n",
      "\n",
      "[243] Train loss: 0.4624206890\n",
      "Vail set: Loss: 0.9354, Accuracy: 4283/6975 ( 61%)\n",
      "\n",
      "[244] Train loss: 0.4794301662\n",
      "Vail set: Loss: 0.9350, Accuracy: 4286/6975 ( 61%)\n",
      "\n",
      "[245] Train loss: 0.4883307273\n",
      "Vail set: Loss: 0.9343, Accuracy: 4342/6975 ( 62%)\n",
      "\n",
      "[246] Train loss: 0.4857655092\n",
      "Vail set: Loss: 0.9355, Accuracy: 4226/6975 ( 61%)\n",
      "\n",
      "[247] Train loss: 0.4967531053\n",
      "Vail set: Loss: 0.9352, Accuracy: 4261/6975 ( 61%)\n",
      "\n",
      "[248] Train loss: 0.4912098755\n",
      "Vail set: Loss: 0.9348, Accuracy: 4248/6975 ( 61%)\n",
      "\n",
      "[249] Train loss: 0.4795284369\n",
      "Vail set: Loss: 0.9350, Accuracy: 4241/6975 ( 61%)\n",
      "\n",
      "[250] Train loss: 0.4725310586\n",
      "Vail set: Loss: 0.9333, Accuracy: 4400/6975 ( 63%)\n",
      "\n",
      "[251] Train loss: 0.4610236428\n",
      "Vail set: Loss: 0.9345, Accuracy: 4323/6975 ( 62%)\n",
      "\n",
      "[252] Train loss: 0.4511125803\n",
      "Vail set: Loss: 0.9335, Accuracy: 4383/6975 ( 63%)\n",
      "\n",
      "[253] Train loss: 0.4488697735\n",
      "Vail set: Loss: 0.9329, Accuracy: 4416/6975 ( 63%)\n",
      "\n",
      "[254] Train loss: 0.4508157871\n",
      "Vail set: Loss: 0.9331, Accuracy: 4435/6975 ( 64%)\n",
      "\n",
      "[255] Train loss: 0.4576719837\n",
      "Vail set: Loss: 0.9332, Accuracy: 4404/6975 ( 63%)\n",
      "\n",
      "[256] Train loss: 0.4512352640\n",
      "Vail set: Loss: 0.9335, Accuracy: 4400/6975 ( 63%)\n",
      "\n",
      "[257] Train loss: 0.4440171892\n",
      "Vail set: Loss: 0.9333, Accuracy: 4402/6975 ( 63%)\n",
      "\n",
      "[258] Train loss: 0.4335062135\n",
      "Vail set: Loss: 0.9350, Accuracy: 4190/6975 ( 60%)\n",
      "\n",
      "[259] Train loss: 0.4553728559\n",
      "Vail set: Loss: 0.9323, Accuracy: 4501/6975 ( 65%)\n",
      "\n",
      "[260] Train loss: 0.4705072089\n",
      "Vail set: Loss: 0.9333, Accuracy: 4384/6975 ( 63%)\n",
      "\n",
      "[261] Train loss: 0.4722820965\n",
      "Vail set: Loss: 0.9330, Accuracy: 4429/6975 ( 63%)\n",
      "\n",
      "[262] Train loss: 0.4569670905\n",
      "Vail set: Loss: 0.9325, Accuracy: 4500/6975 ( 65%)\n",
      "\n",
      "[263] Train loss: 0.4441876509\n",
      "Vail set: Loss: 0.9333, Accuracy: 4469/6975 ( 64%)\n",
      "\n",
      "[264] Train loss: 0.5174158107\n",
      "Vail set: Loss: 0.9378, Accuracy: 4192/6975 ( 60%)\n",
      "\n",
      "[265] Train loss: 0.5107183283\n",
      "Vail set: Loss: 0.9357, Accuracy: 4309/6975 ( 62%)\n",
      "\n",
      "[266] Train loss: 0.4938226277\n",
      "Vail set: Loss: 0.9362, Accuracy: 4227/6975 ( 61%)\n",
      "\n",
      "[267] Train loss: 0.4947829051\n",
      "Vail set: Loss: 0.9355, Accuracy: 4246/6975 ( 61%)\n",
      "\n",
      "[268] Train loss: 0.4819827307\n",
      "Vail set: Loss: 0.9346, Accuracy: 4341/6975 ( 62%)\n",
      "\n",
      "[269] Train loss: 0.4725167134\n",
      "Vail set: Loss: 0.9344, Accuracy: 4324/6975 ( 62%)\n",
      "\n",
      "[270] Train loss: 0.4738856391\n",
      "Vail set: Loss: 0.9331, Accuracy: 4463/6975 ( 64%)\n",
      "\n",
      "[271] Train loss: 0.4818795204\n",
      "Vail set: Loss: 0.9358, Accuracy: 4207/6975 ( 60%)\n",
      "\n",
      "[272] Train loss: 0.4704589584\n",
      "Vail set: Loss: 0.9341, Accuracy: 4399/6975 ( 63%)\n",
      "\n",
      "[273] Train loss: 0.4667588061\n",
      "Vail set: Loss: 0.9336, Accuracy: 4441/6975 ( 64%)\n",
      "\n",
      "[274] Train loss: 0.4623382200\n",
      "Vail set: Loss: 0.9336, Accuracy: 4430/6975 ( 64%)\n",
      "\n",
      "[275] Train loss: 0.4658386491\n",
      "Vail set: Loss: 0.9334, Accuracy: 4456/6975 ( 64%)\n",
      "\n",
      "[276] Train loss: 0.4719556538\n",
      "Vail set: Loss: 0.9340, Accuracy: 4407/6975 ( 63%)\n",
      "\n",
      "[277] Train loss: 0.5010967580\n",
      "Vail set: Loss: 0.9345, Accuracy: 4469/6975 ( 64%)\n",
      "\n",
      "[278] Train loss: 0.4911836277\n",
      "Vail set: Loss: 0.9347, Accuracy: 4472/6975 ( 64%)\n",
      "\n",
      "[279] Train loss: 0.4799918792\n",
      "Vail set: Loss: 0.9357, Accuracy: 4312/6975 ( 62%)\n",
      "\n",
      "[280] Train loss: 0.4749098182\n",
      "Vail set: Loss: 0.9336, Accuracy: 4546/6975 ( 65%)\n",
      "\n",
      "Model Saved.\n",
      "[281] Train loss: 0.4586880543\n",
      "Vail set: Loss: 0.9337, Accuracy: 4524/6975 ( 65%)\n",
      "\n",
      "[282] Train loss: 0.4543191650\n",
      "Vail set: Loss: 0.9343, Accuracy: 4444/6975 ( 64%)\n",
      "\n",
      "[283] Train loss: 0.4610408685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/code/exam/baseline.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.141/opt/ml/input/code/exam/baseline.ipynb#ch0000037vscode-remote?line=0'>1</a>\u001b[0m train(lstm1, optimizer, dataset0_train_dataloader, dataset0_test_dataloader, \u001b[39mNone\u001b[39;49;00m, device)\n",
      "\u001b[1;32m/opt/ml/input/code/exam/baseline.ipynb Cell 18'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, vali_loader, scheduler, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.141/opt/ml/input/code/exam/baseline.ipynb#ch0000036vscode-remote?line=37'>38</a>\u001b[0m         vali_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(logit, label)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.141/opt/ml/input/code/exam/baseline.ipynb#ch0000036vscode-remote?line=38'>39</a>\u001b[0m         pred \u001b[39m=\u001b[39m logit\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.141/opt/ml/input/code/exam/baseline.ipynb#ch0000036vscode-remote?line=39'>40</a>\u001b[0m         correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39;49meq(label\u001b[39m.\u001b[39;49mview_as(pred))\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.141/opt/ml/input/code/exam/baseline.ipynb#ch0000036vscode-remote?line=40'>41</a>\u001b[0m vali_acc \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(vali_loader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B115.85.181.141/opt/ml/input/code/exam/baseline.ipynb#ch0000036vscode-remote?line=41'>42</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mVail set: Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m ( \u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(vali_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(vali_loader), correct, \u001b[39mlen\u001b[39m(vali_loader\u001b[39m.\u001b[39mdataset), \u001b[39m100\u001b[39m \u001b[39m*\u001b[39m correct \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(vali_loader\u001b[39m.\u001b[39mdataset)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(lstm1, optimizer, dataset0_train_dataloader, dataset0_test_dataloader, None, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Accuracy가 가장 뛰어난 모델을 불러옵니다.\n",
    "checkpoint = torch.load('./saved/best_model.pth')\n",
    "model = LSTM1(num_classes, input_size, hidden_size, num_layers, seq_length)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# transfer learning\n",
    "model.seq_length = 800\n",
    "model.num_classes = 11\n",
    "model.hidden_size = 128\n",
    "model.fc = nn.Linear(128, 11)\n",
    "model.to(device)\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=lr)  # adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_train(model, optimizer, train_loader, scheduler, device): \n",
    "    model.to(device)\n",
    "    n = len(train_loader)\n",
    "    \n",
    "    criterion = F1_Loss(classes=11).to(device)\n",
    "    best_loss = 9999999999\n",
    "    \n",
    "    for epoch in range(1, epochs+1): \n",
    "        model.train() \n",
    "        running_loss = 0.0\n",
    "            \n",
    "        for img, label in iter(train_loader):\n",
    "            img, label = img.to(device), label.to(device) \n",
    "            optimizer.zero_grad() \n",
    "        \n",
    "            logit = model(img)\n",
    "            loss = criterion(logit, label)\n",
    "            \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            running_loss += loss.item()\n",
    "              \n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss / len(train_loader)))\n",
    "        torch.save(model.state_dict(), './saved/transfer_best_model.pth') \n",
    "        print('Model Saved.')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 0.9173920921\n",
      "Model Saved.\n",
      "[2] Train loss: 0.8985827565\n",
      "Model Saved.\n",
      "[3] Train loss: 0.8737818088\n",
      "Model Saved.\n",
      "[4] Train loss: 0.8614775964\n",
      "Model Saved.\n",
      "[5] Train loss: 0.8482056090\n",
      "Model Saved.\n",
      "[6] Train loss: 0.8440420542\n",
      "Model Saved.\n",
      "[7] Train loss: 0.8274247306\n",
      "Model Saved.\n",
      "[8] Train loss: 0.8159001810\n",
      "Model Saved.\n",
      "[9] Train loss: 0.8100082023\n",
      "Model Saved.\n",
      "[10] Train loss: 0.8040526850\n",
      "Model Saved.\n",
      "[11] Train loss: 0.7889873981\n",
      "Model Saved.\n",
      "[12] Train loss: 0.7808127744\n",
      "Model Saved.\n",
      "[13] Train loss: 0.7736287798\n",
      "Model Saved.\n",
      "[14] Train loss: 0.7703659534\n",
      "Model Saved.\n",
      "[15] Train loss: 0.7656122105\n",
      "Model Saved.\n",
      "[16] Train loss: 0.7503376773\n",
      "Model Saved.\n",
      "[17] Train loss: 0.7799177681\n",
      "Model Saved.\n",
      "[18] Train loss: 0.7390077710\n",
      "Model Saved.\n",
      "[19] Train loss: 0.7280135666\n",
      "Model Saved.\n",
      "[20] Train loss: 0.7169122015\n",
      "Model Saved.\n",
      "[21] Train loss: 0.7047115564\n",
      "Model Saved.\n",
      "[22] Train loss: 0.7010176522\n",
      "Model Saved.\n",
      "[23] Train loss: 0.6922353932\n",
      "Model Saved.\n",
      "[24] Train loss: 0.6849587645\n",
      "Model Saved.\n",
      "[25] Train loss: 0.6716689127\n",
      "Model Saved.\n"
     ]
    }
   ],
   "source": [
    "transfer_train(model, optimizer, dataset1_train_dataloader, None, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in iter(test_loader):\n",
    "            img = img[0].to(device)\n",
    "\n",
    "            pred_logit = model(img)\n",
    "            pred_logit = pred_logit.argmax(dim=1, keepdim=True).squeeze(1)\n",
    "\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./saved/transfer_best_model.pth')\n",
    "model = lstm1\n",
    "model.seq_length = 800\n",
    "model.hidden_size = 128\n",
    "model.num_classes = 11\n",
    "model.fc = nn.Linear(128, 11)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(device)\n",
    "# Inference\n",
    "preds = predict(model, dataset1_test_dataloader, device)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>class10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79</td>\n",
       "      <td>class10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>865</td>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>866</td>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>867</td>\n",
       "      <td>class10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>868</td>\n",
       "      <td>class10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>869</td>\n",
       "      <td>class5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    label\n",
       "0             9   class5\n",
       "1            38   class5\n",
       "2            46  class10\n",
       "3            65   class5\n",
       "4            79  class10\n",
       "..          ...      ...\n",
       "202         865   class5\n",
       "203         866   class5\n",
       "204         867  class10\n",
       "205         868  class10\n",
       "206         869   class5\n",
       "\n",
       "[207 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/opt/ml/input/code/exam/submission_sample.csv', index_col=None)\n",
    "predicted = ['class'+str(i) for i in preds]\n",
    "df['label'] = predicted\n",
    "df.to_csv('submission.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
